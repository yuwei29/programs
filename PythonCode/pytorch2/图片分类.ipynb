{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fb6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5690a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8a5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32 \n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9fc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  the 1-D data to  2-D  image data form:\n",
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8934ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.to_numpy()\n",
    "Y=X[:,0]\n",
    "X=X[:,1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653d7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[0:39000]\n",
    "Y_train=Y[:39000]\n",
    "X_val=X[39000:42000]\n",
    "Y_val=Y[39000:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4aa03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((39000,1,28,28))\n",
    "X_val=X_val.reshape((3000,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5698d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(X_train)\n",
    "X_val=torch.tensor(X_val)\n",
    "y_train=torch.tensor(Y_train)\n",
    "y_val=torch.tensor(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb73f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to(device=device, dtype=dtype)\n",
    "y_train=y_train.to(device=device, dtype=torch.long)\n",
    "X_val=X_val.to(device=device, dtype=dtype)\n",
    "y_val=y_val.to(device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9dd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch%d:\"%(e+1))\n",
    "        for t in range(390):\n",
    "            model.train()  # put model to training mode\n",
    "            batch_mask=np.random.choice(39000,100)\n",
    "            x=X_train[batch_mask]\n",
    "            y=y_train[batch_mask]\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                #check_accuracy_part34(loader_val, model)\n",
    "                #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6c3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1,64,(3,3),padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(64,64,(3,3),padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),\n",
    "    \n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64,128,(3,3),padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Conv2d(128,128,(3,3),padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),  # 128*7*7  \n",
    "    \n",
    "    \n",
    "    nn.BatchNorm2d(128),\n",
    "    \n",
    "    Flatten(),\n",
    "    nn.Linear(128*7*7,128),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Linear(128,10),\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb7184db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:\n",
      "Iteration 0, loss = 2.5833\n",
      "Iteration 100, loss = 0.0249\n",
      "Iteration 200, loss = 0.0495\n",
      "Iteration 300, loss = 0.0156\n",
      "Epoch2:\n",
      "Iteration 0, loss = 0.1215\n",
      "Iteration 100, loss = 0.0443\n",
      "Iteration 200, loss = 0.0192\n",
      "Iteration 300, loss = 0.1040\n",
      "Epoch3:\n",
      "Iteration 0, loss = 0.0417\n",
      "Iteration 100, loss = 0.0036\n",
      "Iteration 200, loss = 0.0118\n",
      "Iteration 300, loss = 0.0035\n",
      "Epoch4:\n",
      "Iteration 0, loss = 0.0084\n",
      "Iteration 100, loss = 0.0068\n",
      "Iteration 200, loss = 0.0057\n",
      "Iteration 300, loss = 0.0049\n",
      "Epoch5:\n",
      "Iteration 0, loss = 0.0019\n",
      "Iteration 100, loss = 0.0074\n",
      "Iteration 200, loss = 0.0142\n",
      "Iteration 300, loss = 0.0016\n",
      "Epoch6:\n",
      "Iteration 0, loss = 0.0008\n",
      "Iteration 100, loss = 0.0195\n",
      "Iteration 200, loss = 0.0020\n",
      "Iteration 300, loss = 0.0058\n",
      "Epoch7:\n",
      "Iteration 0, loss = 0.0009\n",
      "Iteration 100, loss = 0.0011\n",
      "Iteration 200, loss = 0.0009\n",
      "Iteration 300, loss = 0.0077\n",
      "Epoch8:\n",
      "Iteration 0, loss = 0.0085\n",
      "Iteration 100, loss = 0.1473\n",
      "Iteration 200, loss = 0.0007\n",
      "Iteration 300, loss = 0.0057\n",
      "Epoch9:\n",
      "Iteration 0, loss = 0.0014\n",
      "Iteration 100, loss = 0.0003\n",
      "Iteration 200, loss = 0.0023\n",
      "Iteration 300, loss = 0.0019\n",
      "Epoch10:\n",
      "Iteration 0, loss = 0.0004\n",
      "Iteration 100, loss = 0.0103\n",
      "Iteration 200, loss = 0.0008\n",
      "Iteration 300, loss = 0.0086\n"
     ]
    }
   ],
   "source": [
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9c4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(model):\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "            scores = model(X_val)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y_val).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            acc = float(num_correct) / num_samples\n",
    "            print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91177e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2982 / 3000 correct (99.40)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy_part34(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914def3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch180env]",
   "language": "python",
   "name": "conda-env-torch180env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
